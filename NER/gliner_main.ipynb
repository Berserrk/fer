{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/firaterman/Documents/fer/berserk3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# Initialize GLiNER with the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /Users/firaterman/Documents/data/gliner\n",
      "/Users/firaterman/Documents/fer/berserk3/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"../../data/gliner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wladimir Putin => Person\n",
      "Weihnachten => Date\n",
      "Joe Biden => Person\n",
      "Dr. Smith => Person\n",
      "John Smith => Person\n",
      "Hillary Clinton => Person\n",
      "Wladimir Putin => Person\n"
     ]
    }
   ],
   "source": [
    "# Sample text for entity prediction\n",
    "text = \"\"\"\n",
    "Der russische Präsident Wladimir Putin hat heute keine neuen Richtlinien verkündet. Die letzten bekannten Äußerungen Putins stammen von einer Fragerunde vor Weihnachten, bei der er über verschiedene Themen wie Syrien, den Krieg gegen die Ukraine und die niedrige Geburtenrate in Russland sprach4\n",
    ". Bezüglich Joe Biden, Dr. Smith, John Smith und Hillary Clinton liegen keine aktuellen Informationen aus den gegebenen Suchergebnissen vor. Die Suchergebnisse konzentrieren sich hauptsächlich auf Wladimir Putin und enthalten keine Informationen über aktuelle Aktivitäten dieser amerikanischen Politiker oder Personen.\n",
    "\"\"\"\n",
    "\n",
    "# Labels for entity prediction\n",
    "# Most GLiNER models should work best when entity types are in lower case or title case\n",
    "labels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
