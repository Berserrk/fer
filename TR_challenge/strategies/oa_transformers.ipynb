{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18000 documents\n"
     ]
    }
   ],
   "source": [
    "# rag_classifier.py\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizerFast, BertModel, BertForSequenceClassification,\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizerFast,\n",
    ")\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ----- 1. Load and parse JSON lines -----\n",
    "data = []\n",
    "with open('../data/TRDataChallenge2023.txt', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        try:\n",
    "            data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping line {i+1} due to parse error\")\n",
    "\n",
    "print(f\"Loaded {len(data)} documents\")\n",
    "\n",
    "# ----- 2. Prepare DataFrame -----\n",
    "df = pd.DataFrame(data)\n",
    "df['postures'] = df['postures'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "def flatten_sections(secs):\n",
    "    paragraphs = []\n",
    "    for sec in secs:\n",
    "        paragraphs.extend(sec.get('paragraphs', []))\n",
    "    return ' '.join(paragraphs)\n",
    "df['text'] = df['sections'].apply(flatten_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentId</th>\n",
       "      <th>postures</th>\n",
       "      <th>sections</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ib4e590e0a55f11e8a5d58a2c8dcb28b5</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Plaintiff Dw...</td>\n",
       "      <td>Plaintiff Dwight Watson (“Husband”) appeals fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ib06ab4d056a011e98c7a8e995225dbf9</td>\n",
       "      <td>[Appellate Review, Sentencing or Penalty Phase...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['After pleadi...</td>\n",
       "      <td>After pleading guilty, William Jerome Howard, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iaa3e3390b93111e9ba33b03ae9101fb2</td>\n",
       "      <td>[Motion to Compel Arbitration, On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Frederick Gr...</td>\n",
       "      <td>Frederick Greene, the plaintiff below, derivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I0d4dffc381b711e280719c3f0e80bdd0</td>\n",
       "      <td>[On Appeal, Review of Administrative Decision]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Appeal from ...</td>\n",
       "      <td>Appeal from an amended judgment of the Supreme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I82c7ef10d6d111e8aec5b23c3317c9c0</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Order, Supre...</td>\n",
       "      <td>Order, Supreme Court, New York County (Arthur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>Ia5743cf0e4b611e99e94fcbef715f24d</td>\n",
       "      <td>[Appellate Review]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['¶1 On Februa...</td>\n",
       "      <td>¶1 On February 5, 2017, a jury in the Fifth Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>I974c18f08f1611e998e8870e22e55653</td>\n",
       "      <td>[Objection to Proof of Claim]</td>\n",
       "      <td>[{'headtext': 'ORDER OVERRULING DEBTOR'S OBJEC...</td>\n",
       "      <td>On April 17, 2019 the Court held a hearing on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>Idaaa92f0886f11e998e8870e22e55653</td>\n",
       "      <td>[Appellate Review, Trial or Guilt Phase Motion...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['A jury convi...</td>\n",
       "      <td>A jury convicted Antonio Avila Medrano of Cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>I247a8420677e11e9a072efd81f5238d6</td>\n",
       "      <td>[Appellate Review, Jury Selection Challenge or...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Defendant Ch...</td>\n",
       "      <td>Defendant Charles York Walker, Jr., appeals fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>Id5f8b500e68311e78c5db03c58f2bc1d</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['A parent has...</td>\n",
       "      <td>A parent has a fundamental right, protected by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              documentId  \\\n",
       "0      Ib4e590e0a55f11e8a5d58a2c8dcb28b5   \n",
       "1      Ib06ab4d056a011e98c7a8e995225dbf9   \n",
       "2      Iaa3e3390b93111e9ba33b03ae9101fb2   \n",
       "3      I0d4dffc381b711e280719c3f0e80bdd0   \n",
       "4      I82c7ef10d6d111e8aec5b23c3317c9c0   \n",
       "...                                  ...   \n",
       "17995  Ia5743cf0e4b611e99e94fcbef715f24d   \n",
       "17996  I974c18f08f1611e998e8870e22e55653   \n",
       "17997  Idaaa92f0886f11e998e8870e22e55653   \n",
       "17998  I247a8420677e11e9a072efd81f5238d6   \n",
       "17999  Id5f8b500e68311e78c5db03c58f2bc1d   \n",
       "\n",
       "                                                postures  \\\n",
       "0                                            [On Appeal]   \n",
       "1      [Appellate Review, Sentencing or Penalty Phase...   \n",
       "2              [Motion to Compel Arbitration, On Appeal]   \n",
       "3         [On Appeal, Review of Administrative Decision]   \n",
       "4                                            [On Appeal]   \n",
       "...                                                  ...   \n",
       "17995                                 [Appellate Review]   \n",
       "17996                      [Objection to Proof of Claim]   \n",
       "17997  [Appellate Review, Trial or Guilt Phase Motion...   \n",
       "17998  [Appellate Review, Jury Selection Challenge or...   \n",
       "17999                                        [On Appeal]   \n",
       "\n",
       "                                                sections  \\\n",
       "0      [{'headtext': '', 'paragraphs': ['Plaintiff Dw...   \n",
       "1      [{'headtext': '', 'paragraphs': ['After pleadi...   \n",
       "2      [{'headtext': '', 'paragraphs': ['Frederick Gr...   \n",
       "3      [{'headtext': '', 'paragraphs': ['Appeal from ...   \n",
       "4      [{'headtext': '', 'paragraphs': ['Order, Supre...   \n",
       "...                                                  ...   \n",
       "17995  [{'headtext': '', 'paragraphs': ['¶1 On Februa...   \n",
       "17996  [{'headtext': 'ORDER OVERRULING DEBTOR'S OBJEC...   \n",
       "17997  [{'headtext': '', 'paragraphs': ['A jury convi...   \n",
       "17998  [{'headtext': '', 'paragraphs': ['Defendant Ch...   \n",
       "17999  [{'headtext': '', 'paragraphs': ['A parent has...   \n",
       "\n",
       "                                                    text  \n",
       "0      Plaintiff Dwight Watson (“Husband”) appeals fr...  \n",
       "1      After pleading guilty, William Jerome Howard, ...  \n",
       "2      Frederick Greene, the plaintiff below, derivat...  \n",
       "3      Appeal from an amended judgment of the Supreme...  \n",
       "4      Order, Supreme Court, New York County (Arthur ...  \n",
       "...                                                  ...  \n",
       "17995  ¶1 On February 5, 2017, a jury in the Fifth Ju...  \n",
       "17996  On April 17, 2019 the Court held a hearing on ...  \n",
       "17997  A jury convicted Antonio Avila Medrano of Cons...  \n",
       "17998  Defendant Charles York Walker, Jr., appeals fr...  \n",
       "17999  A parent has a fundamental right, protected by...  \n",
       "\n",
       "[18000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# Convert postures list to multi-hot\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df['postures'])\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=(len(df) - 100)/len(df), random_state=42)\n",
    "\n",
    "for train_idx, sample_idx in msss.split(df, Y):\n",
    "    sample_df = df.iloc[sample_idx]\n",
    "\n",
    "sample_df = sample_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29efbcdca1e4246b4edc5b72cd3b818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding train embeddings:   0%|          | 0/3594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, DPRContextEncoder, DPRContextEncoderTokenizerFast, Trainer, TrainingArguments\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_json('../data/TRDataChallenge2023.txt', lines=True)\n",
    "df['postures'] = df['postures'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "def flatten_sections(secs):\n",
    "    paragraphs = []\n",
    "    for sec in secs:\n",
    "        paragraphs.extend(sec.get('paragraphs', []))\n",
    "    return ' '.join(paragraphs)\n",
    "df['text'] = df['sections'].apply(flatten_sections)\n",
    "\n",
    "# Encode labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df['postures'])\n",
    "N_labels = len(mlb.classes_)\n",
    "\n",
    "# Sample 1000 representative docs\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=(len(df) - 30)/len(df), random_state=42)\n",
    "for train_idx, sample_idx in msss.split(df, Y):\n",
    "    df = df.iloc[sample_idx]\n",
    "    Y = Y[sample_idx]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split data\n",
    "train_df, val_df, Y_train, Y_val = train_test_split(df, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# DPR encoder setup\n",
    "dpr_tok = DPRContextEncoderTokenizerFast.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "dpr_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_embs = []\n",
    "\n",
    "batch_sz = 4\n",
    "for i in tqdm(range(0, len(train_texts), batch_sz), desc=\"Encoding train embeddings\"):\n",
    "    batch = train_texts[i:i+batch_sz]\n",
    "    toks = dpr_tok(batch, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        embs = dpr_encoder(**toks).pooler_output.detach().cpu().numpy()\n",
    "    train_embs.append(embs)\n",
    "\n",
    "train_embs = np.vstack(train_embs)\n",
    "dim = train_embs.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "faiss.normalize_L2(train_embs)\n",
    "index.add(train_embs)\n",
    "\n",
    "# BERT classifier\n",
    "bert_tok = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "class RagClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels, n_neighbors=3):\n",
    "        super().__init__()\n",
    "        self.nbrs = n_neighbors\n",
    "        self.dpr_encoder = dpr_encoder\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels, problem_type='multi_label_classification')\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        with torch.no_grad():\n",
    "            q_emb = self.dpr_encoder(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "            q_emb = torch.nn.functional.normalize(q_emb, p=2, dim=1)\n",
    "        sims, idxs = index.search(q_emb.cpu().numpy(), self.nbrs)\n",
    "\n",
    "        batch_text = bert_tok.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        concat_texts = [\n",
    "            qt + \" [SEP] \" + \" [SEP] \".join(train_texts[j] for j in idxs_i)\n",
    "            for qt, idxs_i in zip(batch_text, idxs)\n",
    "        ]\n",
    "\n",
    "        toks = bert_tok(concat_texts, truncation=True, padding=True, max_length=512, return_tensors='pt').to(input_ids.device)\n",
    "\n",
    "        return self.bert(input_ids=toks['input_ids'], attention_mask=toks['attention_mask'], labels=labels)\n",
    "\n",
    "# Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        toks = self.tokenizer(self.texts[idx], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "        item = {k: v.squeeze(0) for k, v in toks.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "train_ds = TextDataset(train_df['text'].tolist(), Y_train, bert_tok)\n",
    "val_ds = TextDataset(val_df['text'].tolist(), Y_val, bert_tok)\n",
    "\n",
    "# Training setup\n",
    "model = RagClassifier(num_labels=N_labels, n_neighbors=3)\n",
    "args = TrainingArguments(\n",
    "    output_dir='rag_out',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='rag_logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berserk3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
